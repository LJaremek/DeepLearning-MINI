{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_spectrogram(file_path: str):\n",
    "    waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "    transformer = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sr, n_fft=2048, hop_length=512, n_mels=64\n",
    "        )\n",
    "\n",
    "    spectrogram = transformer(waveform)\n",
    "    spectrogram = torchaudio.transforms.AmplitudeToDB()(spectrogram)\n",
    "    return spectrogram.squeeze(0).transpose(0, 1)\n",
    "\n",
    "\n",
    "def vector_quantize(features, n_clusters: int = 100):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    all_data = np.vstack([f.numpy() for f in features])\n",
    "    kmeans.fit(all_data)\n",
    "\n",
    "    quantized_features = [\n",
    "        torch.tensor(kmeans.predict(f.numpy()), dtype=torch.long)\n",
    "        for f in features\n",
    "        ]\n",
    "\n",
    "    return quantized_features, kmeans\n",
    "\n",
    "\n",
    "def load_and_quantize_data(\n",
    "        directory: str,\n",
    "        target_labels: list[str] = [\"up\", \"down\", \"left\", \"right\"],\n",
    "        n_clusters: int = 100\n",
    "        ) -> tuple:\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        if label in target_labels:\n",
    "            class_dir = os.path.join(directory, label)\n",
    "            for fname in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, fname)\n",
    "                spectrogram = audio_to_spectrogram(file_path)\n",
    "                features.append(spectrogram)\n",
    "                labels.append(label)\n",
    "\n",
    "    quantized_features, kmeans = vector_quantize(features, n_clusters)\n",
    "\n",
    "    return quantized_features, labels, kmeans\n",
    "\n",
    "\n",
    "def pad_sequences(sequences, pad_value: int = 0):\n",
    "    max_len = max([s.size(0) for s in sequences])\n",
    "\n",
    "    padded_sequences = [\n",
    "        torch.nn.functional.pad(s, (0, max_len - s.size(0)), value=pad_value)\n",
    "        for s in sequences\n",
    "        ]\n",
    "\n",
    "    return torch.stack(padded_sequences)\n",
    "\n",
    "\n",
    "class AudioTransformer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_tokens: int, dim_model: int, num_heads: int,\n",
    "            num_classes: int, dim_feedforward: int = 2048,\n",
    "            num_layers: int = 1, dropout: int = 0.1\n",
    "            ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim_model, nhead=num_heads,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout\n",
    "            )\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, num_layers=num_layers\n",
    "            )\n",
    "\n",
    "        self.fc = nn.Linear(dim_model, num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src)  # Replace tokens with embeddings\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.mean(dim=1)\n",
    "        output = self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader, criterion) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            labels = labels.long()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    # print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Studia\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/kmeans_model.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels, kmeans = load_and_quantize_data(\"data/train\")\n",
    "\n",
    "dump(kmeans, \"models/kmeans_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_padded = pad_sequences(features)\n",
    "\n",
    "train_features_padded, test_features_padded, train_labels, test_labels = train_test_split(\n",
    "    features_padded, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = torch.tensor(label_encoder.fit_transform(train_labels))\n",
    "test_labels_encoded = torch.tensor(label_encoder.transform(test_labels))\n",
    "dump(label_encoder, \"models/label_encoder.joblib\")\n",
    "\n",
    "train_dataset = TensorDataset(train_features_padded, train_labels_encoded)\n",
    "test_dataset = TensorDataset(test_features_padded, test_labels_encoded)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Studia\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1424 Test loss: 1.0072 Test acc: 59.65\n",
      "Epoch 2, Loss: 0.9723 Test loss: 0.9144 Test acc: 66.26\n",
      "Epoch 3, Loss: 0.9285 Test loss: 0.9607 Test acc: 63.09\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 100  # Same as number of clusters\n",
    "\n",
    "model = AudioTransformer(\n",
    "    num_tokens=num_tokens,\n",
    "    dim_model=256,\n",
    "    num_heads=8,\n",
    "    num_classes=len(np.unique(train_labels))\n",
    "    )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_dict = {\n",
    "    \"test\": [],\n",
    "    \"train\": []\n",
    "}\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    loss_sum = []\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum.append(loss.item())\n",
    "    \n",
    "    test_loss, test_accuracy = eval_model(model, test_loader, criterion)\n",
    "\n",
    "    loss_ = np.mean(np.array(loss_sum))\n",
    "\n",
    "    loss_dict[\"test\"].append(test_loss)\n",
    "    loss_dict[\"train\"].append(loss_)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {round(loss_, 4)} Test loss: {round(test_loss, 4)} Test acc: {round(test_accuracy, 2):4}\")\n",
    "    if len(loss_dict[\"test\"]) > 1 and loss_dict[\"test\"][-2] <= loss_dict[\"test\"][-1]:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
