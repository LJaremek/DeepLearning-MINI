{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_spectrogram(file_path):\n",
    "    waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "    transformer = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sr, n_fft=2048, hop_length=512, n_mels=64\n",
    "        )\n",
    "\n",
    "    spectrogram = transformer(waveform)\n",
    "    spectrogram = torchaudio.transforms.AmplitudeToDB()(spectrogram)\n",
    "    return spectrogram.squeeze(0).transpose(0, 1)  # Transpose to have time steps on the first dimension\n",
    "\n",
    "\n",
    "def vector_quantize(features, n_clusters=100):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    all_data = np.vstack([f.numpy() for f in features])\n",
    "    kmeans.fit(all_data)\n",
    "\n",
    "    quantized_features = [\n",
    "        torch.tensor(kmeans.predict(f.numpy()), dtype=torch.long)\n",
    "        for f in features\n",
    "        ]\n",
    "\n",
    "    return quantized_features, kmeans\n",
    "\n",
    "\n",
    "def load_and_quantize_data(\n",
    "        directory,\n",
    "        target_labels=[\"up\", \"down\", \"left\", \"right\"],\n",
    "        n_clusters=100\n",
    "        ):\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        if label in target_labels:\n",
    "            class_dir = os.path.join(directory, label)\n",
    "            for fname in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, fname)\n",
    "                spectrogram = audio_to_spectrogram(file_path)\n",
    "                features.append(spectrogram)\n",
    "                labels.append(label)\n",
    "\n",
    "    quantized_features, _ = vector_quantize(features, n_clusters)\n",
    "\n",
    "    return quantized_features, labels\n",
    "\n",
    "\n",
    "def pad_sequences(sequences, pad_value=0):\n",
    "    # Oblicz maksymalną długość sekwencji\n",
    "    max_len = max([s.size(0) for s in sequences])\n",
    "\n",
    "    # Wypełnij każdy tensor w liście, aby miał maksymalną długość\n",
    "    padded_sequences = [\n",
    "        torch.nn.functional.pad(s, (0, max_len - s.size(0)), value=pad_value)\n",
    "        for s in sequences\n",
    "        ]\n",
    "\n",
    "    # Stos wszystkich wypełnionych tensorów\n",
    "    return torch.stack(padded_sequences)\n",
    "\n",
    "\n",
    "class AudioTransformer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_tokens, dim_model, num_heads, num_classes,\n",
    "            dim_feedforward=2048, num_layers=1, dropout=0.1\n",
    "            ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim_model, nhead=num_heads,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout\n",
    "            )\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, num_layers=num_layers\n",
    "            )\n",
    "\n",
    "        self.fc = nn.Linear(dim_model, num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src)  # Replace tokens with embeddings\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.mean(dim=1)  # Average over the sequence for classification\n",
    "        output = self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and vector quantize\n",
    "features, labels = load_and_quantize_data(\"data/train\")\n",
    "# test_features, test_labels = load_and_quantize_data(\"data/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Użycie funkcji pad_sequences\n",
    "features_padded = pad_sequences(features)\n",
    "\n",
    "train_features_padded, test_features_padded, train_labels, test_labels = train_test_split(\n",
    "    features_padded, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Convert to tensor and encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = torch.tensor(label_encoder.fit_transform(train_labels))\n",
    "test_labels_encoded = torch.tensor(label_encoder.transform(test_labels))\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(train_features_padded, train_labels_encoded)\n",
    "test_dataset = TensorDataset(test_features_padded, test_labels_encoded)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.248584811091423\n",
      "Epoch 2, Loss: 1.0252215158939362\n",
      "Epoch 3, Loss: 0.9800149464607238\n",
      "Epoch 4, Loss: 0.9249011129140854\n",
      "Epoch 5, Loss: 0.9184495961666107\n",
      "Epoch 6, Loss: 0.9024950790405274\n",
      "Epoch 7, Loss: 0.8926821839809418\n",
      "Epoch 8, Loss: 0.880125060081482\n",
      "Epoch 9, Loss: 0.8714895620942116\n",
      "Epoch 10, Loss: 0.8625024443864823\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "num_tokens = 100  # Same as number of clusters\n",
    "model = AudioTransformer(\n",
    "    num_tokens=num_tokens,\n",
    "    dim_model=256,\n",
    "    num_heads=8,\n",
    "    num_classes=len(np.unique(train_labels))\n",
    "    )\n",
    "\n",
    "# Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    loss_sum = []\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {np.mean(np.array(loss_sum))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9864, Test Accuracy: 60.25%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Przełącz model w tryb oceny\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        labels = labels.long()  # Upewnij się, że etykiety są typu long\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:1486: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 5.90k/5.90k [00:00<?, ?B/s]\n",
      "Downloading readme: 100%|██████████| 5.29k/5.29k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 471M/471M [15:55<00:00, 493kB/s]   \n",
      "Generating train split: 654 examples [00:00, 6519.81 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "    num_rows: 654\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at anton-l/xtreme_s_xlsr_300m_minds14 were not used when initializing Wav2Vec2ForSequenceClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at anton-l/xtreme_s_xlsr_300m_minds14 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"audio-classification\",\n",
    "    model=\"anton-l/xtreme_s_xlsr_300m_minds14\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\1234o\\.cache\\huggingface\\hub\\models--MIT--ast-finetuned-speech-commands-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/60/d7/60d71667758e20658a4fa800f231bfd977499f69891b6532aa045462cf00cbfc/bde0444230420731a792dc26c873420800a655625c8dc4323d980623e74a464b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1715206752&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTIwNjc1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82MC9kNy82MGQ3MTY2Nzc1OGUyMDY1OGE0ZmE4MDBmMjMxYmZkOTc3NDk5ZjY5ODkxYjY1MzJhYTA0NTQ2MmNmMDBjYmZjL2JkZTA0NDQyMzA0MjA3MzFhNzkyZGMyNmM4NzM0MjA4MDBhNjU1NjI1YzhkYzQzMjNkOTgwNjIzZTc0YTQ2NGI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=YddmR8%7EP4K%7EGs8Xb-nzOlIcZ88nbQQNdSKsqHBoQeqy2tbaA8QSKGD5VXeomK4OAPmpObaX%7EsrdCtVCLQLzafgpd5Z4nUBcKDqAJ572Eo4i15-Sb6xZjZtZ1rV9MLJJ6MxfR2VmVTEMPNJevfJ6nvnORWu%7EqQ4ZOLQ3lei0NEW6mFU--PJ5xYywkxN-BPCwBHzdmZHCyGtZDZJ0Fx%7E3OfzCYVLJsendJ8pgK64hSlsc6LGQWE9A6BRjEtU9Jln3P%7ERS0DyjKaogEel1LrpxghZm8TpzxW7mKB5YPW%7EOVrsF8rx2FJfFb8BEihYU6Xjw72tJ-zYrGu6HEgSFQ5qRIMw__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model MIT/ast-finetuned-speech-commands-v2 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForAudioClassification'>, <class 'transformers.models.audio_spectrogram_transformer.modeling_audio_spectrogram_transformer.ASTForAudioClassification'>). See the original errors:\n\nwhile loading with AutoModelForAudioClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 737, in _error_catcher\n    yield\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 862, in _raw_read\n    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 845, in _fp_read\n    return self._fp.read(amt) if amt is not None else self._fp.read()\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py\", line 479, in read\n    s = self.fp.read(amt)\n        ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py\", line 707, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py\", line 1252, in recv_into\n    return self.read(nbytes, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py\", line 1104, in read\n    return self._sslobj.read(len, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTimeoutError: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py\", line 816, in generate\n    yield from self.raw.stream(chunk_size, decode_content=True)\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 1043, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 935, in read\n    data = self._raw_read(amt)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 861, in _raw_read\n    with self._error_catcher():\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 742, in _error_catcher\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 535, in http_get\n    for chunk in r.iter_content(chunk_size=DOWNLOAD_CHUNK_SIZE):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py\", line 822, in generate\n    raise ConnectionError(e)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py\", line 963, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 793, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 491, in _make_request\n    raise new_e\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n    self._validate_conn(conn)\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1099, in _validate_conn\n    conn.connect()\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 616, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 205, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x00000284FB6FE540>: Failed to resolve 'cdn-lfs.huggingface.co' ([Errno 11001] getaddrinfo failed)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 847, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /repos/60/d7/60d71667758e20658a4fa800f231bfd977499f69891b6532aa045462cf00cbfc/bde0444230420731a792dc26c873420800a655625c8dc4323d980623e74a464b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1715206752&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTIwNjc1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82MC9kNy82MGQ3MTY2Nzc1OGUyMDY1OGE0ZmE4MDBmMjMxYmZkOTc3NDk5ZjY5ODkxYjY1MzJhYTA0NTQ2MmNmMDBjYmZjL2JkZTA0NDQyMzA0MjA3MzFhNzkyZGMyNmM4NzM0MjA4MDBhNjU1NjI1YzhkYzQzMjNkOTgwNjIzZTc0YTQ2NGI~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=YddmR8~P4K~Gs8Xb-nzOlIcZ88nbQQNdSKsqHBoQeqy2tbaA8QSKGD5VXeomK4OAPmpObaX~srdCtVCLQLzafgpd5Z4nUBcKDqAJ572Eo4i15-Sb6xZjZtZ1rV9MLJJ6MxfR2VmVTEMPNJevfJ6nvnORWu~qQ4ZOLQ3lei0NEW6mFU--PJ5xYywkxN-BPCwBHzdmZHCyGtZDZJ0Fx~3OfzCYVLJsendJ8pgK64hSlsc6LGQWE9A6BRjEtU9Jln3P~RS0DyjKaogEel1LrpxghZm8TpzxW7mKB5YPW~OVrsF8rx2FJfFb8BEihYU6Xjw72tJ-zYrGu6HEgSFQ5qRIMw__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000284FB6FE540>: Failed to resolve 'cdn-lfs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 563, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3318, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 398, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 119, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1492, in hf_hub_download\n    http_get(\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 552, in http_get\n    return http_get(\n           ^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 456, in http_get\n    r = _request_wrapper(\n        ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 392, in _request_wrapper\n    response = get_session().request(method=method, url=url, **params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 68, in send\n    return super().send(request, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: (MaxRetryError('HTTPSConnectionPool(host=\\'cdn-lfs.huggingface.co\\', port=443): Max retries exceeded with url: /repos/60/d7/60d71667758e20658a4fa800f231bfd977499f69891b6532aa045462cf00cbfc/bde0444230420731a792dc26c873420800a655625c8dc4323d980623e74a464b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1715206752&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTIwNjc1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82MC9kNy82MGQ3MTY2Nzc1OGUyMDY1OGE0ZmE4MDBmMjMxYmZkOTc3NDk5ZjY5ODkxYjY1MzJhYTA0NTQ2MmNmMDBjYmZjL2JkZTA0NDQyMzA0MjA3MzFhNzkyZGMyNmM4NzM0MjA4MDBhNjU1NjI1YzhkYzQzMjNkOTgwNjIzZTc0YTQ2NGI~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=YddmR8~P4K~Gs8Xb-nzOlIcZ88nbQQNdSKsqHBoQeqy2tbaA8QSKGD5VXeomK4OAPmpObaX~srdCtVCLQLzafgpd5Z4nUBcKDqAJ572Eo4i15-Sb6xZjZtZ1rV9MLJJ6MxfR2VmVTEMPNJevfJ6nvnORWu~qQ4ZOLQ3lei0NEW6mFU--PJ5xYywkxN-BPCwBHzdmZHCyGtZDZJ0Fx~3OfzCYVLJsendJ8pgK64hSlsc6LGQWE9A6BRjEtU9Jln3P~RS0DyjKaogEel1LrpxghZm8TpzxW7mKB5YPW~OVrsF8rx2FJfFb8BEihYU6Xjw72tJ-zYrGu6HEgSFQ5qRIMw__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000284FB6FE540>: Failed to resolve \\'cdn-lfs.huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 7587c9ea-6a0d-401f-9845-6d088361c470)')\n\nwhile loading with ASTForAudioClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py\", line 963, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 793, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 491, in _make_request\n    raise new_e\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n    self._validate_conn(conn)\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1099, in _validate_conn\n    conn.connect()\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 616, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 205, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x00000284FB6E2600>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 847, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /MIT/ast-finetuned-speech-commands-v2/resolve/main/tf_model.h5 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000284FB6E2600>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3397, in from_pretrained\n    if has_file(pretrained_model_name_or_path, TF2_WEIGHTS_NAME, **has_file_kwargs):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 627, in has_file\n    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=10)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py\", line 100, in head\n    return request(\"head\", url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /MIT/ast-finetuned-speech-commands-v2/resolve/main/tf_model.h5 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000284FB6E2600>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m classifier_commands \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio-classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMIT/ast-finetuned-speech-commands-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:906\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 906\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    917\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py:296\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    295\u001b[0m             error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 296\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    297\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m         )\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     framework \u001b[38;5;241m=\u001b[39m infer_framework(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model MIT/ast-finetuned-speech-commands-v2 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForAudioClassification'>, <class 'transformers.models.audio_spectrogram_transformer.modeling_audio_spectrogram_transformer.ASTForAudioClassification'>). See the original errors:\n\nwhile loading with AutoModelForAudioClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 737, in _error_catcher\n    yield\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 862, in _raw_read\n    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 845, in _fp_read\n    return self._fp.read(amt) if amt is not None else self._fp.read()\n           ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py\", line 479, in read\n    s = self.fp.read(amt)\n        ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py\", line 707, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py\", line 1252, in recv_into\n    return self.read(nbytes, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py\", line 1104, in read\n    return self._sslobj.read(len, buffer)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTimeoutError: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py\", line 816, in generate\n    yield from self.raw.stream(chunk_size, decode_content=True)\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 1043, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 935, in read\n    data = self._raw_read(amt)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 861, in _raw_read\n    with self._error_catcher():\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py\", line 742, in _error_catcher\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 535, in http_get\n    for chunk in r.iter_content(chunk_size=DOWNLOAD_CHUNK_SIZE):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py\", line 822, in generate\n    raise ConnectionError(e)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py\", line 963, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 793, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 491, in _make_request\n    raise new_e\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n    self._validate_conn(conn)\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1099, in _validate_conn\n    conn.connect()\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 616, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 205, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x00000284FB6FE540>: Failed to resolve 'cdn-lfs.huggingface.co' ([Errno 11001] getaddrinfo failed)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 847, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /repos/60/d7/60d71667758e20658a4fa800f231bfd977499f69891b6532aa045462cf00cbfc/bde0444230420731a792dc26c873420800a655625c8dc4323d980623e74a464b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1715206752&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTIwNjc1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82MC9kNy82MGQ3MTY2Nzc1OGUyMDY1OGE0ZmE4MDBmMjMxYmZkOTc3NDk5ZjY5ODkxYjY1MzJhYTA0NTQ2MmNmMDBjYmZjL2JkZTA0NDQyMzA0MjA3MzFhNzkyZGMyNmM4NzM0MjA4MDBhNjU1NjI1YzhkYzQzMjNkOTgwNjIzZTc0YTQ2NGI~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=YddmR8~P4K~Gs8Xb-nzOlIcZ88nbQQNdSKsqHBoQeqy2tbaA8QSKGD5VXeomK4OAPmpObaX~srdCtVCLQLzafgpd5Z4nUBcKDqAJ572Eo4i15-Sb6xZjZtZ1rV9MLJJ6MxfR2VmVTEMPNJevfJ6nvnORWu~qQ4ZOLQ3lei0NEW6mFU--PJ5xYywkxN-BPCwBHzdmZHCyGtZDZJ0Fx~3OfzCYVLJsendJ8pgK64hSlsc6LGQWE9A6BRjEtU9Jln3P~RS0DyjKaogEel1LrpxghZm8TpzxW7mKB5YPW~OVrsF8rx2FJfFb8BEihYU6Xjw72tJ-zYrGu6HEgSFQ5qRIMw__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000284FB6FE540>: Failed to resolve 'cdn-lfs.huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 563, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3318, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 398, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 119, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1492, in hf_hub_download\n    http_get(\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 552, in http_get\n    return http_get(\n           ^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 456, in http_get\n    r = _request_wrapper(\n        ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 392, in _request_wrapper\n    response = get_session().request(method=method, url=url, **params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 68, in send\n    return super().send(request, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: (MaxRetryError('HTTPSConnectionPool(host=\\'cdn-lfs.huggingface.co\\', port=443): Max retries exceeded with url: /repos/60/d7/60d71667758e20658a4fa800f231bfd977499f69891b6532aa045462cf00cbfc/bde0444230420731a792dc26c873420800a655625c8dc4323d980623e74a464b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1715206752&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTIwNjc1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82MC9kNy82MGQ3MTY2Nzc1OGUyMDY1OGE0ZmE4MDBmMjMxYmZkOTc3NDk5ZjY5ODkxYjY1MzJhYTA0NTQ2MmNmMDBjYmZjL2JkZTA0NDQyMzA0MjA3MzFhNzkyZGMyNmM4NzM0MjA4MDBhNjU1NjI1YzhkYzQzMjNkOTgwNjIzZTc0YTQ2NGI~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=YddmR8~P4K~Gs8Xb-nzOlIcZ88nbQQNdSKsqHBoQeqy2tbaA8QSKGD5VXeomK4OAPmpObaX~srdCtVCLQLzafgpd5Z4nUBcKDqAJ572Eo4i15-Sb6xZjZtZ1rV9MLJJ6MxfR2VmVTEMPNJevfJ6nvnORWu~qQ4ZOLQ3lei0NEW6mFU--PJ5xYywkxN-BPCwBHzdmZHCyGtZDZJ0Fx~3OfzCYVLJsendJ8pgK64hSlsc6LGQWE9A6BRjEtU9Jln3P~RS0DyjKaogEel1LrpxghZm8TpzxW7mKB5YPW~OVrsF8rx2FJfFb8BEihYU6Xjw72tJ-zYrGu6HEgSFQ5qRIMw__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000284FB6FE540>: Failed to resolve \\'cdn-lfs.huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 7587c9ea-6a0d-401f-9845-6d088361c470)')\n\nwhile loading with ASTForAudioClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py\", line 963, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 793, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 491, in _make_request\n    raise new_e\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n    self._validate_conn(conn)\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1099, in _validate_conn\n    conn.connect()\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 616, in connect\n    self.sock = sock = self._new_conn()\n                       ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py\", line 205, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x00000284FB6E2600>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 847, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /MIT/ast-finetuned-speech-commands-v2/resolve/main/tf_model.h5 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000284FB6E2600>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3397, in from_pretrained\n    if has_file(pretrained_model_name_or_path, TF2_WEIGHTS_NAME, **has_file_kwargs):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 627, in has_file\n    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=10)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py\", line 100, in head\n    return request(\"head\", url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\1234o\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /MIT/ast-finetuned-speech-commands-v2/resolve/main/tf_model.h5 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000284FB6E2600>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\n\n"
     ]
    }
   ],
   "source": [
    "classifier_commands = pipeline(\n",
    "    \"audio-classification\", model=\"MIT/ast-finetuned-speech-commands-v2\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
