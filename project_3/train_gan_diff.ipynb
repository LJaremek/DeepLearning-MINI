{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "from diffusers import UNet2DModel, DDPMScheduler\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "epochs = 200\n",
    "image_size = 64\n",
    "data_path = \"data/bedroom\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
    "pipeline.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, image_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256, 0.8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512, 0.8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024, 0.8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, image_size * image_size * 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 3, self.image_size, self.image_size)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size * image_size * 3, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "generator = Generator(latent_dim, image_size).to(device)\n",
    "discriminator = Discriminator(image_size).to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_path, transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(imgs.size(0), 1, device=device, dtype=torch.float)\n",
    "        fake = torch.zeros(imgs.size(0), 1, device=device, dtype=torch.float)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = torch.randn(imgs.size(0), latent_dim, device=device)\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        # Loss for fake images\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        # Total discriminator loss\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "    print(f\"[Epoch {epoch}/{epochs}]\", end=\" \")\n",
    "    print(f\"[D loss: {d_loss.item()}]\", end=\" \")\n",
    "    print(f\"[G loss: {g_loss.item()}]\")\n",
    "\n",
    "    # Save models\n",
    "    torch.save(generator.state_dict(), f\"models/generator_epoch_{epoch}.pth\")\n",
    "    torch.save(discriminator.state_dict(), f\"models/discriminator_epoch_{epoch}.pth\")\n",
    "\n",
    "    # Save generated images every epoch\n",
    "    save_image(gen_imgs.data[:25], f\"images/{epoch}.png\", nrow=5, normalize=True)\n",
    "\n",
    "    # Generate samples using the diffusion model\n",
    "    diffusion_samples = pipeline(num_inference_steps=50).images\n",
    "    save_image(diffusion_samples[:25], f\"images/diffusion_{epoch}.png\", nrow=5, normalize=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
